% Rapport de l'étude Homère
@TechReport{homere_2023,
  author = {Pigeon, Caroline and Baltenneck, Nicolas and Galiano, Anna Rita and Uzan, Gérard},
  title  = {Étude Homère - Étude nationale sur la déficience visuelle},
  year   = {2023},
  groups = {Déficience visuelle},
}

@Article{gaunet_verbal_2006,
  author   = {Gaunet, Florence},
  journal  = {Universal Access in the Information Society},
  title    = {Verbal guidance rules for a localized wayfinding aid intended for blind-pedestrians in urban areas},
  year     = {2006},
  issn     = {1615-5289, 1615-5297},
  month    = may,
  number   = {4},
  pages    = {338--353},
  volume   = {4},
  doi      = {10.1007/s10209-003-0086-2},
  groups   = {Description verbale},
  keywords = {Intersection, Outdoor navigation, Verbal route description},
  language = {en},
  url      = {http://link.springer.com/10.1007/s10209-003-0086-2},
  urldate  = {2020-10-21},
}

@Article{gaunet_exploring_2005,
  author     = {Gaunet, Florence and Briffault, Xavier},
  journal    = {Human-Computer Interaction},
  title      = {Exploring the {Functional} {Specifications} of a {Localized} {Wayfinding} {Verbal} {Aid} for {Blind} {Pedestrians}: {Simple} and {Structured} {Urban} {Areas}},
  year       = {2005},
  issn       = {0737-0024},
  month      = sep,
  number     = {3},
  pages      = {267--314},
  volume     = {20},
  doi        = {10.1207/s15327051hci2003_2},
  language   = {en},
  shorttitle = {Exploring the {Functional} {Specifications} of a {Localized} {Wayfinding} {Verbal} {Aid} for {Blind} {Pedestrians}},
  url        = {http://www.tandfonline.com/doi/abs/10.1207/s15327051hci2003_2},
  urldate    = {2020-10-20},
}

@Article{boeing_osmnx_2017,
  author     = {Boeing, Geoff},
  journal    = {Computers, Environment and Urban Systems},
  title      = {{OSMnx}: {New} methods for acquiring, constructing, analyzing, and visualizing complex street networks},
  year       = {2017},
  issn       = {0198-9715},
  month      = sep,
  pages      = {126--139},
  volume     = {65},
  abstract   = {Urban scholars have studied street networks in various ways, but there are data availability and consistency limitations to the current urban planning/street network analysis literature. To address these challenges, this article presents OSMnx, a new tool to make the collection of data and creation and analysis of street networks simple, consistent, automatable and sound from the perspectives of graph theory, transportation, and urban design. OSMnx contributes five significant capabilities for researchers and practitioners: first, the automated downloading of political boundaries and building footprints; second, the tailored and automated downloading and constructing of street network data from OpenStreetMap; third, the algorithmic correction of network topology; fourth, the ability to save street networks to disk as shapefiles, GraphML, or SVG files; and fifth, the ability to analyze street networks, including calculating routes, projecting and visualizing networks, and calculating metric and topological measures. These measures include those common in urban design and transportation studies, as well as advanced measures of the structure and topology of the network. Finally, this article presents a simple case study using OSMnx to construct and analyze street networks in Portland, Oregon.},
  doi        = {10.1016/j.compenvurbsys.2017.05.004},
  groups     = {Manipulation des données},
  keywords   = {OpenStreetMap, Visualization, GIS, Transportation, Complex networks, Python, Resilience, Street network, Urban design, Urban form},
  language   = {en},
  shorttitle = {{OSMnx}},
  url        = {https://www.sciencedirect.com/science/article/pii/S0198971516303970},
  urldate    = {2022-04-08},
}

@Book{ratelle_manuel_2019,
  author    = {Ratelle, Agathe and Couturier, Julie-Anne},
  publisher = {PU Montréal},
  title     = {Manuel d'intervention en orientation et mobilité},
  year      = {2019},
  isbn      = {978-2-7606-3905-8},
  month     = jan,
  abstract  = {Ce manuel unique en français rend compte d'un domaine de pointe très spécialisé encore peu connu dans la population en général. Il aborde l'orientation et la mobilité des personnes non voyantes en présentant les techniques et les habiletés de déplacement ainsi que les nombreuses stratégies d'intervention privilégiées en milieu de réadaptation. Il met également en lumière des processus complexes comme l'audition, la kinésiologie et la psychologie cognitive et se penche sur le rôle important de l'environnement dans l'atteinte de l'autonomie. S'inspirant des pratiques américaines et des ouvrages anglophones les plus actuels, les autrices démontrent leur parfaite connaissance de ces aspects interconnectés essentiels à la pratique professionnelle et enrichissent le sujet par leur propre expertise. Leur savoir prend appui sur une riche bibliographie et sur des aspects importants de la profession : son historique, le rôle du spécialiste et la description des techniques et des étapes de l'enseignement, avec des conseils à la clé et de nombreuses observations tirées de leur expérience.},
  groups    = {Déficience visuelle},
  language  = {Français},
}

@Article{Wabinski2019,
  author    = {Wabiński, Jakub and Mościcka, Albina},
  journal   = {ISPRS International Journal of Geo-Information},
  title     = {Automatic ({Tactile}) {Map} {Generation}—{A} {Systematic} {Literature} {Review}},
  year      = {2019},
  issn      = {2220-9964},
  month     = jul,
  number    = {7},
  pages     = {293},
  volume    = {8},
  abstract  = {This paper presents a systematic literature review that reflects the current state of research in the field of algorithms and models for map generalization, the existing solutions for automatic (tactile) map generation, as well as good practices for designing spatial databases for the purposes of automatic map development. A total number of over 500 primary studies were screened in order to identify the most relevant research on automatic (tactile) map generation from the last decade. The reviewed papers revealed many existing solutions in the field of automatic map production, as well as algorithms (e.g., Douglas–Peucker, Visvalingam–Whyatt) and models (e.g., GAEL, CartACom) for data generalization that might be used to transform traditional spatial data into the haptic form, suitable for blind and visually impaired people. However, it turns out that a comprehensive solution for automatic tactile map generation does not exist.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  doi       = {10.3390/ijgi8070293},
  file      = {:Wabinski2019 - Automatic (Tactile) Map Generation—A Systematic Literature Review.pdf:PDF;:Wabinski2019 - Automatic (Tactile) Map Generation—A Systematic Literature Review.pdf:PDF},
  groups    = {Cartes tactiles},
  keywords  = {generalization, algorithm, model, map automation, tactile maps, maps for blind and visually impaired},
  language  = {en},
  publisher = {Multidisciplinary Digital Publishing Institute},
  url       = {https://www.mdpi.com/2220-9964/8/7/293},
  urldate   = {2023-07-04},
}

@InProceedings{Minatani2010,
  author    = {Minatani, Kazunori and Watanabe, Tetsuya and Yamaguchi, Toshimitsu and Watanabe, Ken and Akiyama, Joji and Miyagi, Manabi and Oouchi, Susumu},
  booktitle = {Computers {Helping} {People} with {Special} {Needs}},
  title     = {Tactile {Map} {Automated} {Creation} {System} to {Enhance} the {Mobility} of {Blind} {Persons}—{Its} {Design} {Concept} and {Evaluation} through {Experiment}},
  year      = {2010},
  address   = {Berlin, Heidelberg},
  editor    = {Miesenberger, Klaus and Klaus, Joachim and Zagler, Wolfgang and Karshmer, Arthur},
  pages     = {534--540},
  publisher = {Springer},
  series    = {Lecture {Notes} in {Computer} {Science}},
  abstract  = {The authors have developed a tactile map creation system (TMACS). It is intended to assist blind persons’ independent mobility. For this purpose, the system was designed to produce tactile maps, to be manipulated by the blind person and to support producing tactile maps of arbitrary locations of Japan. Through group interviews with blind persons, the authors collected information on what kind of strategies are useful for independent walk and what kind of objects can function as landmarks. TMACS is developed to make good use of these information. From the walking experiment, some assumptions which were made by the authors were confirmed. On the other hand, some unexpected or contradicted results were observed on the usefulness of landmarks and the cause of losing right routes.},
  doi       = {10.1007/978-3-642-14100-3_80},
  file      = {:(Lecture Notes in Computer Science 6180 Information Systems and Applications, incl. Internet_Web, and HCI) Latifa Al-Abdulkarim, Areej Al-Wabil, Maha Al-Yahya, Abeer Al-Humaimeedy (auth.), Klaus Miese.pdf:PDF},
  groups    = {Cartes tactiles},
  isbn      = {9783642141003},
  keywords  = {Blind person, Visually Impaired, Tactile Map, Independent Mobility, Orientation and Mobility},
  language  = {en},
}

@Article{Miele2006,
  author     = {Miele, Joshua A. and Landau, Steven and Gilden, Deborah},
  journal    = {British Journal of Visual Impairment},
  title      = {Talking {TMAP}: {Automated} generation of audio-tactile maps using {Smith}-{Kettlewell}'s {TMAP} software},
  year       = {2006},
  issn       = {0264-6196},
  month      = may,
  number     = {2},
  pages      = {93--100},
  volume     = {24},
  abstract   = {Traditional tactile cartography is complicated by problems associated with braille labeling and feature annotation. Audio-tactile display techniques can address many of these issues by associating spoken information and sounds with specific map elements. This article introduces Talking TMAP – a collaborative effort between The Smith-Kettlewell Eye Research Institute and Touch Graphics, Inc. Talking TMAP combines existing tools such as the World Wide Web, geographic information systems, braille embossers and touch tablet technology in new ways to produce a system capable of creating detailed and accurate audio-tactile street maps of any neighborhood. The article describes software design, user interface and plans for future implementation.},
  doi        = {10.1177/0264619606064436},
  file       = {SAGE PDF Full Text:https\://journals.sagepub.com/doi/pdf/10.1177/0264619606064436:application/pdf},
  groups     = {Cartes tactiles},
  language   = {en},
  publisher  = {SAGE Publications Ltd},
  shorttitle = {Talking {TMAP}},
  url        = {https://doi.org/10.1177/0264619606064436},
  urldate    = {2023-07-05},
}

@InProceedings{Miele2004,
  author    = {Miele, Joshua A.},
  booktitle = {Proceedings of CSUN International Conference on Technology and Persons with Disabilities},
  title     = {Tactile map automated production (TMAP): Using GIS data to generate braille maps},
  year      = {2004},
  groups    = {Cartes tactiles},
}

@InProceedings{Watanabe2014,
  author    = {Watanabe, Tetsuya and Yamaguchi, Toshimitsu and Koda, Satoko and Minatani, Kazunori},
  booktitle = {Computers {Helping} {People} with {Special} {Needs}},
  title     = {Tactile {Map} {Automated} {Creation} {System} {Using} {OpenStreetMap}},
  year      = {2014},
  address   = {Cham},
  editor    = {Miesenberger, Klaus and Fels, Deborah and Archambault, Dominique and Peňáz, Petr and Zagler, Wolfgang},
  pages     = {42--49},
  publisher = {Springer International Publishing},
  series    = {Lecture {Notes} in {Computer} {Science}},
  abstract  = {We have developed a Web-based tactile map automated creation system tmacs. Users simply type in an address or the name of a building and the system instantly creates an image of a tactile map, which is then printed on capsule paper and raised up by a heater. This time we modified this system to deal with OpenStreetMap (OSM). The advantage of using OSM data is that tmacs becomes to be able to create tactile maps of any location in the world and include information which is useful for blind people such as tactile paving. Another feature of the new system is that sighted users can change the point and scale of a tactile map in the same way as a regular Google Map. We are exploring the possibility of increasing the number of countries whose tactile maps can be created with tmacs.},
  doi       = {10.1007/978-3-319-08599-9_7},
  file      = {:Watanabe2014 - Tactile Map Automated Creation System Using OpenStreetMap.html:URL},
  groups    = {Cartes tactiles},
  isbn      = {9783319085999},
  keywords  = {Blind People, Tactile Map, Tactile Perception, OpenStreetMap, Automated Creation},
  language  = {en},
}

@InProceedings{Cervenka2016,
  author    = {Červenka, Petr and Břinda, Karel and Hanousková, Michaela and Hofman, Petr and Seifert, Radek},
  booktitle = {Computers {Helping} {People} with {Special} {Needs}},
  title     = {Blind {Friendly} {Maps}},
  year      = {2016},
  address   = {Cham},
  editor    = {Miesenberger, Klaus and Bühler, Christian and Penaz, Petr},
  pages     = {131--138},
  publisher = {Springer International Publishing},
  series    = {Lecture {Notes} in {Computer} {Science}},
  abstract  = {Blind people can now use maps located at Mapy.cz, thanks to the long-standing joint efforts of the ELSA Center at the Czech Technical University in Prague, the Teiresias Center at Masaryk University, and the company Seznam.cz. Conventional map underlays are automatically adjusted so that they could be read through touch after being printed on microcapsule paper, which opens a whole new perspective in the use of tactile maps. Users may select an area of their choice in the Czech Republic (only within its boundaries, for the time being) and also the production of tactile maps, including the preparation of the map underlays, takes no more than several minutes.},
  doi       = {10.1007/978-3-319-41267-2_18},
  file      = {:Cervenka2016 - Blind Friendly Maps.html:URL},
  groups    = {Cartes tactiles},
  isbn      = {9783319412672},
  keywords  = {Tactile map, Tactile perception, Blind people, Web maps accessibility, Automated geodata processing},
  language  = {en},
}

@Article{Wabinski2022,
  author     = {Wabiński, Jakub and Mościcka, Albina and Touya, Guillaume},
  journal    = {The Cartographic Journal},
  title      = {Guidelines for {Standardizing} the {Design} of {Tactile} {Maps}: {A} {Review} of {Research} and {Best} {Practice}},
  year       = {2022},
  issn       = {0008-7041},
  month      = jul,
  number     = {3},
  pages      = {239--258},
  volume     = {59},
  abstract   = {Accessibility to tactile maps is limited due to their expensive and time-consuming development. Acceleration of their production requires standardized design guidelines that consider symbol design and production methods. In this paper, based on a review of research and best practice, we summarize knowledge on how to design tactile maps properly and provide a selection of highly legible, recommended symbols for the compilation of tactile maps. We also examine generalization constraints and other design parameters that are necessary for the standardization of tactile mapping. Finally, we explore differences in tactile map design depending upon the selected production method. Over the years, many useful guidelines have been developed although they remain unknown to the wider audience. There is still a long way to go in creating a global standard for the design of tactile maps.},
  doi        = {10.1080/00087041.2022.2097760},
  file       = {Full Text PDF:https\://www.tandfonline.com/doi/pdf/10.1080/00087041.2022.2097760:application/pdf},
  groups     = {Cartes tactiles},
  keywords   = {Tactile maps, design principles, standardization, symbology, production methods, guidelines},
  publisher  = {Taylor \& Francis},
  shorttitle = {Guidelines for {Standardizing} the {Design} of {Tactile} {Maps}},
  url        = {https://doi.org/10.1080/00087041.2022.2097760},
  urldate    = {2023-07-05},
}

@Article{Stampach2016,
  author    = {Štampach, Radim and Mulíčková, Eva},
  journal   = {Journal of Maps},
  title     = {Automated generation of tactile maps},
  year      = {2016},
  issn      = {null},
  month     = nov,
  number    = {sup1},
  pages     = {532--540},
  volume    = {12},
  abstract  = {The Support Centre for Students with Special Needs at Masaryk University (the Teiresias Centre) in Brno, Czech Republic asked the team at the Department of Geography at the Faculty of Science to develop a technological procedure for the preparation of tactile maps from available sources of data. Most users would be blind and visually impaired students of Masaryk University. A set of scripts in Python language was prepared for the ArcGIS environment. The scripts prepare the source data, modify the layers, generate the layout of map sheets and export map sheets. The grid of map sheets covers the whole area of Brno City. Printed map sheets are combinable into larger areas. The scale of each map sheet is 1:2500.},
  doi       = {10.1080/17445647.2016.1196622},
  file      = {Full Text PDF:https\://www.tandfonline.com/doi/pdf/10.1080/17445647.2016.1196622:application/pdf},
  groups    = {Cartes tactiles},
  keywords  = {Tactile map, tyflomap, blind, visually impaired, ArcGIS, Python},
  publisher = {Taylor \& Francis},
  url       = {https://doi.org/10.1080/17445647.2016.1196622},
  urldate   = {2023-07-05},
}

@Article{Touya2019,
  author     = {Touya, Guillaume and Christophe, Sidonie and Favreau, Jean-Marie and Ben Rhaiem, Amine},
  journal    = {International Journal of Cartography},
  title      = {Automatic derivation of on-demand tactile maps for visually impaired people: first experiments and research agenda},
  year       = {2019},
  issn       = {2372-9333},
  month      = jan,
  number     = {1},
  pages      = {67--91},
  volume     = {5},
  abstract   = {Tactile maps are essential tools for visually impaired people to comprehend space and to support the simple pedestrian trips made difficult by their disability. Tactile maps are created manually and printed by specialists, and it takes a large amount of time to create a new one, which prevents using them on demand for everyday use. As a consequence, researchers and cartographers try to automate this creation process, but the existing automated derivation processes do not include generalization or advanced stylization steps, which limits their effectiveness. This paper reports first experiments to include such complex automated cartography processes to provide on-demand tactile maps for visually impaired people. These first experiments were more intended to raise real research issues than solve them, and the paper discusses these issues in a research agenda to achieve automatically derived tactile maps.},
  doi        = {10.1080/23729333.2018.1486784},
  file       = {Full Text PDF:https\://www.tandfonline.com/doi/pdf/10.1080/23729333.2018.1486784:application/pdf},
  groups     = {Cartes tactiles},
  keywords   = {Cartography, tactile map, visual impairment, map generalization, stylization, 3D printing, scale, cognition},
  publisher  = {Taylor \& Francis},
  shorttitle = {Automatic derivation of on-demand tactile maps for visually impaired people},
  url        = {https://doi.org/10.1080/23729333.2018.1486784},
  urldate    = {2023-07-05},
}

@Article{FillieresRiveau2020,
  author    = {Fillières-Riveau, Gauthier and Favreau, Jean-Marie and Barra, Vincent and Touya, Guillaume},
  journal   = {Revue Internationale de Géomatique},
  title     = {Génération de cartes tactiles photoréalistes pour personnes déficientes visuelles par apprentissage profond},
  year      = {2020},
  issn      = {1260-5875, 2116-7060},
  month     = jan,
  number    = {1-2},
  pages     = {105--126},
  volume    = {30},
  abstract  = {Les cartes tactiles photoréalistes sont un des outils mobilisés par les personnes en situation de déficience visuelle pour appréhender leur environnement urbain proche, notamment dans le cadre de la mobilité, pour la traversée de carrefours par exemple. Ces cartes sont aujourd’hui principalement fabriquées artisanalement. Dans cet article, nous proposons une approche permettant de produire une segmentation sémantique d’une imagerie aérienne de précision, étape centrale de cette fabrication. Les différents éléments d’intérêt tels que trottoirs, passages piétons, ou îlots centraux sont ainsi localisés et tracés dans l’espace urbain. Nous présentons en particulier comment l’augmentation de cette imagerie par des données vectorielles issues d’OpenStreetMap permet d’obtenir par une technique d’apprentissage profond (réseau adverse génératif conditionnel) des résultats significatifs. Après avoir présenté les enjeux de ce travail et un état de l’art des techniques existantes, nous détaillons l’approche proposée, et nous étudions les résultats obtenus, en comparant en particulier les segmentations obtenues sans et avec enrichissement par données vectorielles. Les résultats sont très prometteurs.},
  copyright = {© 2020 Lavoisier},
  doi       = {10.3166/rig.2020.00104},
  file      = {Full Text PDF:https\://rig.revuesonline.com/articles/lvrig/pdf/2020/04/rig00104.pdf:application/pdf},
  groups    = {Cartes tactiles},
  language  = {fr},
  publisher = {Lavoisier},
  url       = {https://rig.revuesonline.com/articles/lvrig/abs/2020/04/rig00104/rig00104.html},
  urldate   = {2023-07-05},
}

@Article{Brock2015,
  author    = {Brock, Anke M. and Truillet, Philippe and Oriola, Bernard and Picard, Delphine and Jouffrais, Christophe},
  journal   = {Human–Computer Interaction},
  title     = {Interactivity {Improves} {Usability} of {Geographic} {Maps} for {Visually} {Impaired} {People}},
  year      = {2015},
  issn      = {0737-0024},
  month     = mar,
  number    = {2},
  pages     = {156--194},
  volume    = {30},
  abstract  = {Tactile relief maps are used by visually impaired people to acquire mental representation of space, but they retain important limitations (limited amount of information, braille text, etc.). Interactive maps may overcome these limitations. However, usability of these two types of maps has never been compared. It is then unknown whether interactive maps are equivalent or even better solutions than traditional raised-line maps. This study presents a comparison of usability of a classical raised-line map versus an interactive map composed of a multitouch screen, a raised-line overlay, and audio output. Both maps were tested by 24 blind participants. We measured usability as efficiency, effectiveness, and satisfaction. Our results show that replacing braille with simple audio-tactile interaction significantly improved efficiency and user satisfaction. Effectiveness was not related to the map type but depended on users’ characteristics as well as the category of assessed spatial knowledge. Long-term evaluation of acquired spatial information revealed that maps, whether interactive or not, are useful to build robust survey-type mental representations in blind users. Altogether, these results are encouraging as they show that interactive maps are a good solution for improving map exploration and cognitive mapping in visually impaired people.},
  doi       = {10.1080/07370024.2014.924412},
  file      = {Full Text PDF:https\://www.tandfonline.com/doi/pdf/10.1080/07370024.2014.924412:application/pdf},
  groups    = {Cartes tactiles},
  publisher = {Taylor \& Francis},
  url       = {https://doi.org/10.1080/07370024.2014.924412},
  urldate   = {2023-07-05},
}

@Article{Jiang2023,
  author   = {Jiang, Yuhao and Lobo, Maria-Jesús and Christophe, Sidonie and Jouffrais, Christophe},
  journal  = {AGILE: GIScience Series},
  title    = {Semi-automated {Pipeline} to {Produce} {Customizable} {Tactile} {Maps} of {Street} {Intersections} for {People} with {Visual} {Impairments}},
  year     = {2023},
  month    = jun,
  pages    = {1--8},
  volume   = {4},
  abstract = {Street intersections are very challenging for people with visual impairments. Manually produced tactile maps are an important support in teaching and assisting independent journeys as they can be customized to serve the visually impaired audience with diverse tactile reading and mobility skills in different use scenarios. But the manual map production involves a huge workload that makes the maps less accessible. This paper explores the possibility of semi-automatically producing customizable tactile maps for street intersections. It presents a parameterized semi-automated pipeline based on OSM data that allows the maps to be customized in size, map features, geometry processing choices, and symbolizations. It produces street intersection maps in two scales of three sizes, with different levels of details and styles.},
  doi      = {10.5194/agile-giss-4-29-2023},
  file     = {ResearchGate Link:https\://www.researchgate.net/publication/371392346_Semi-automated_Pipeline_to_Produce_Customizable_Tactile_Maps_of_Street_Intersections_for_People_with_Visual_Impairments:},
  groups   = {Cartes tactiles},
}

@InProceedings{Josselin2016,
  author   = {Josselin, Didier and Roussel, Dorian and Boularouk, Said and Saidi, Abdelberry and Matrouf, Driss and Bonin, Olivier and Altman, Eitan},
  title    = {Sonorous cartography for sighted and blind people},
  year     = {2016},
  month    = jun,
  abstract = {In this article, we test the usability of a cartographic tool mixing maps and sounds. This tool is developed within QuantumGIS as a plugin prototype. We first present some theoretical reflections about synesthesia. Secondly, we explain the way we «sonificate» the images, by associating colors and recorded chords and sounds. Then we present the results of several usability tests in France with different users, including blind people. We finally conclude on the contributions and the limitations of such a tool and draw some perspectives.},
  file     = {:Josselin2016 - Sonorous Cartography for Sighted and Blind People.pdf:PDF},
  groups   = {Cartographie sonore},
  language = {en},
  url      = {https://hal.science/hal-01338081},
  urldate  = {2023-07-12},
}

@Article{Schito2018,
  author     = {Schito, Joram and Fabrikant, Sara Irina},
  journal    = {International Journal of Geographical Information Science},
  title      = {Exploring maps by sounds: using parameter mapping sonification to make digital elevation models audible},
  year       = {2018},
  issn       = {1365-8816},
  month      = may,
  number     = {5},
  pages      = {874--906},
  volume     = {32},
  abstract   = {This study empirically investigates the potential of auditory displays for spatial data exploration, as an additional means to broaden the accessibility and dissemination of geographic information for a diverse body of users. In a mixed factorial experiment, three parameter mapping sonification methods are empirically evaluated to interactively explore discrete and continuous digital elevation models by auditory means. Contrasting prior sonification research, this study’s unique empirical evidence suggests that participants can indeed successfully interpret sonified displays containing continuous spatial data. Specifically, the auditory variable pitch leads to significantly better response accuracy, compared to the sound variable duration. Background and training has a weak effect on data interpretation performance with the auditory display. The more immersive the experienced soundscape, the better participants can interpret the sonified terrain. These encouraging empirical results indeed suggest that interactive auditory displays might offer additional means to disseminate spatial information, and to increase the accessibility to spatial data, beyond the currently dominant visual paradigm.},
  doi        = {10.1080/13658816.2017.1420192},
  file       = {Full Text PDF:https\://www.tandfonline.com/doi/pdf/10.1080/13658816.2017.1420192:application/pdf},
  groups     = {Cartographie sonore},
  keywords   = {Auditory display, parameter mapping sonification, spatial data analysis, digital elevation model, GIS},
  publisher  = {Taylor \& Francis},
  shorttitle = {Exploring maps by sounds},
  url        = {https://doi.org/10.1080/13658816.2017.1420192},
  urldate    = {2023-07-12},
}

@Article{Edler2019,
  author     = {Edler, Dennis and Kühne, Olaf and Keil, Julian and Dickmann, Frank},
  journal    = {KN - Journal of Cartography and Geographic Information},
  title      = {Audiovisual {Cartography}: {Established} and {New} {Multimedia} {Approaches} to {Represent} {Soundscapes}},
  year       = {2019},
  issn       = {2524-4965},
  month      = may,
  number     = {1},
  pages      = {5--17},
  volume     = {69},
  abstract   = {Since the mid-1990s, sound has been discussed and used in multimedia cartography. There are four main variants of auditory map elements that have been established in the theory and practice of audiovisual cartography, i.e. abstract sounds/abstract sound sequences, speech, music and, especially, audiorealistic sequences representing so-called “soundscapes”. In cartography, soundscapes are often addressed in large-scale representations. The term originates in multidisciplinary landscape research. Empirical findings of landscape research, and especially those of social constructivist landscape research, have shown the relevance of non-visual stimuli for people’s individual impressions and meanings of the experienced landscape. Amongst the non-visual landscape dimensions, the auditory dimension is the most prominent one. As 3D cartography offers new methods and techniques of designing and experiencing highly realistic, incl. photo- and audiorealistic landscape representation, this discipline becomes more and more interesting for simulating and presenting multisensory landscapes and for presenting the results of empirical findings in landscape research. After an introduction to traditional means of audiovisual cartography and the relevance of auditory stimuli for social constructivist approaches of landscape research, a modern software-based method is presented which highlights the opportunity to imbed 3D sound data representing a location’s soundscape into audiovisual 3D environments in Virtual Reality (VR). It is technically based on the cross-platform game engine Unity3D.},
  doi        = {10.1007/s42489-019-00004-4},
  file       = {:Edler2019 - Audiovisual Cartography_ Established and New Multimedia Approaches to Represent Soundscapes.pdf:PDF},
  groups     = {Cartographie sonore},
  keywords   = {Audiovisual cartography, Multimedia cartography, Multisensory cartography, Landscapes, Soundscapes, Virtual reality (VR), Unity 3D, Audiovisuelle Kartographie, Multimediakartographie, Multisensorische Kartographie, Landschaft, Klanglandschaft, Virtual Reality (VR), Unity 3D},
  language   = {en},
  shorttitle = {Audiovisual {Cartography}},
  url        = {https://doi.org/10.1007/s42489-019-00004-4},
  urldate    = {2023-07-12},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: fileDirectoryLatex-jeremy-MacBook-Air-de-Jeremy.local:/Users/jeremy/Developpement/these/chapitres;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:Cartes tactiles\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:Description verbale\;0\;0\;0x8a8a8aff\;\;\;;
1 StaticGroup:Déficience visuelle\;0\;0\;0x8a8a8aff\;\;\;;
1 StaticGroup:Manipulation des données\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:Cartographie sonore\;0\;1\;0x8a8a8aff\;\;\;;
}
